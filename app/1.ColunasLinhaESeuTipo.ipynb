{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas e Linhas no Apache Spark\n",
    "\n",
    "O Apache Spark oferece recursos robustos para trabalhar com colunas e linhas de dados. As colunas são componentes essenciais para selecionar e transformar dados, enquanto as linhas representam entradas individuais em um DataFrame.\n",
    "\n",
    "## Colunas\n",
    "\n",
    "As colunas são objetos que representam uma única coluna em um DataFrame. Elas possuem vários métodos e funcionalidades para transformação e manipulação de dados.\n",
    "\n",
    "| Recurso                                      | Descrição                                                                                          |\n",
    "|---------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| Seleção de Coluna                           | Você pode selecionar uma coluna usando notação de ponto, como `df.coluna`, ou `df[\"coluna\"]`.       |\n",
    "| Operações Matemáticas                       | As colunas suportam operações matemáticas, como soma, subtração, multiplicação e divisão.        |\n",
    "| Funções de Agregação                        | Você pode aplicar funções de agregação, como `count`, `sum`, `avg`, `max` e `min`, a uma coluna. |\n",
    "| Alias (Apelidos)                            | É possível renomear colunas usando o método `.alias(\"novo_nome\")`.                                |\n",
    "| Operações de String                         | Realize operações de string em colunas usando funções como `.substr`, `.lower`, `.replace`, etc. |\n",
    "\n",
    "## Linhas\n",
    "\n",
    "As linhas representam entradas individuais em um DataFrame. Elas contêm os valores para cada coluna em um determinado registro.\n",
    "\n",
    "| Recurso                                      | Descrição                                                                                      |\n",
    "|---------------------------------------------|------------------------------------------------------------------------------------------------|\n",
    "| Acesso a Dados                              | Você pode acessar os dados de uma linha usando notação de ponto ou índices, como `linha.coluna` ou `linha[índice]`. |\n",
    "| Conversão para Dicionário                   | Converta uma linha em um dicionário para fácil manipulação usando o método `.asDict()`.    |\n",
    "| Comparação de Linhas                        | Compare linhas para verificar igualdade ou ordem usando operadores de comparação.         |\n",
    "| Construção de Linhas                        | Crie linhas usando o construtor `Row`. Isso é útil para criar novas linhas em operações de transformação de dados. |\n",
    "\n",
    "## Exemplo de Uso\n",
    "\n",
    "Aqui está um exemplo que demonstra a seleção de colunas e o acesso a dados de linhas em um DataFrame:\n",
    "\n",
    "```python\n",
    "# Importe os módulos necessários\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "# Crie um DataFrame de exemplo\n",
    "data = [Row(nome=\"Alice\", idade=30), Row(nome=\"Bob\", idade=35)]\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Selecione uma coluna\n",
    "nomes = df.select(\"nome\")\n",
    "\n",
    "# Acesse dados da linha\n",
    "primeira_linha = df.first()\n",
    "nome_da_primeira_linha = primeira_linha.nome\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Exemplo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ICAO Empresa Aerea: string (nullable = true)\n",
      " |-- Numero Voo: string (nullable = true)\n",
      " |-- Codigo DI: string (nullable = true)\n",
      " |-- Codigo Tipo Linha: string (nullable = true)\n",
      " |-- ICAO Aerodromo Origem: string (nullable = true)\n",
      " |-- ICAO Aerodromo Destino: string (nullable = true)\n",
      " |-- Partida Prevista: string (nullable = true)\n",
      " |-- Partida Real: string (nullable = true)\n",
      " |-- Chegada Prevista: string (nullable = true)\n",
      " |-- Chegada Real: string (nullable = true)\n",
      " |-- Situacao Voo: string (nullable = true)\n",
      " |-- Codigo Justificativa: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .option(\"encoding\",\"utf-8\")\n",
    "    .option(\"delimiter\",\";\") #ou sep\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"data/landing/VRA/\")\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'ICAO Empresa Aerea'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:818\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[1;32m    817\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mcollectToPython()\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_load_from_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatchedSerializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCPickleSerializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/serializers.py:151\u001b[0m, in \u001b[0;36mFramedSerializer.load_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_with_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/serializers.py:165\u001b[0m, in \u001b[0;36mFramedSerializer._read_with_length\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_with_length\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream):\n\u001b[0;32m--> 165\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[43mread_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m SpecialLengths\u001b[38;5;241m.\u001b[39mEND_OF_DATA_SECTION:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/serializers.py:593\u001b[0m, in \u001b[0;36mread_int\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_int\u001b[39m(stream):\n\u001b[0;32m--> 593\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m length:\n\u001b[1;32m    595\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Codigo Tipo Linha'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Codigo Tipo Linha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (699309396.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df.Chegada Real\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.Chegada Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Chegada_Real'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumnRenamed('Chegada Real','Chegada_Real')\n",
    "df.Chegada_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Situacao_Voo',df['Situacao Voo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ICAO Empresa Aerea: string (nullable = true)\n",
      " |-- Numero Voo: string (nullable = true)\n",
      " |-- Codigo DI: string (nullable = true)\n",
      " |-- Codigo Tipo Linha: string (nullable = true)\n",
      " |-- ICAO Aerodromo Origem: string (nullable = true)\n",
      " |-- ICAO Aerodromo Destino: string (nullable = true)\n",
      " |-- Partida Prevista: string (nullable = true)\n",
      " |-- Partida Real: string (nullable = true)\n",
      " |-- Chegada Prevista: string (nullable = true)\n",
      " |-- Chegada_Real: string (nullable = true)\n",
      " |-- Situacao Voo: string (nullable = true)\n",
      " |-- Codigo Justificativa: string (nullable = true)\n",
      " |-- Situacao_Voo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dataway: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = df.select(df.Chegada_Real.alias(\"dataway\"))\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ICAO Empresa Aerea',\n",
       " 'Numero Voo',\n",
       " 'Codigo DI',\n",
       " 'Codigo Tipo Linha',\n",
       " 'ICAO Aerodromo Origem',\n",
       " 'ICAO Aerodromo Destino',\n",
       " 'Partida Prevista',\n",
       " 'Partida Real',\n",
       " 'Chegada Prevista',\n",
       " 'Chegada_Real',\n",
       " 'Situacao Voo',\n",
       " 'Codigo Justificativa',\n",
       " 'Situacao_Voo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icao_empresa_aerea numero_voo codigo_di codigo_tipo_linha icao_aerodromo_origem icao_aerodromo_destino partida_prevista partida_real chegada_prevista chegada_real situacao_voo codigo_justificativa situacao_voo\n"
     ]
    }
   ],
   "source": [
    "print(*[col.lower().replace(\" \",\"_\") for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- icao_empresa_aerea: string (nullable = true)\n",
      " |-- numero_voo: string (nullable = true)\n",
      " |-- codigo_di: string (nullable = true)\n",
      " |-- codigo_tipo_linha: string (nullable = true)\n",
      " |-- icao_aerodromo_origem: string (nullable = true)\n",
      " |-- icao_aerodromo_destino: string (nullable = true)\n",
      " |-- partida_prevista: string (nullable = true)\n",
      " |-- partida_real: string (nullable = true)\n",
      " |-- chegada_prevista: string (nullable = true)\n",
      " |-- chegada_real: string (nullable = true)\n",
      " |-- situacao_voo: string (nullable = true)\n",
      " |-- codigo_justificativa: string (nullable = true)\n",
      " |-- situacao_voo: string (nullable = true)\n",
      "\n",
      "+------------------+----------+---------+-----------------+---------------------+----------------------+----------------+----------------+----------------+----------------+------------+--------------------+------------+\n",
      "|icao_empresa_aerea|numero_voo|codigo_di|codigo_tipo_linha|icao_aerodromo_origem|icao_aerodromo_destino|partida_prevista|    partida_real|chegada_prevista|    chegada_real|situacao_voo|codigo_justificativa|situacao_voo|\n",
      "+------------------+----------+---------+-----------------+---------------------+----------------------+----------------+----------------+----------------+----------------+------------+--------------------+------------+\n",
      "|               TAM|      9458|        0|                I|                 SBGR|                  SCEL|01/01/2020 06:30|01/01/2020 06:30|01/01/2020 10:40|01/01/2020 10:40|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9201|        0|                N|                 SBSG|                  SBGL|01/01/2020 02:00|01/01/2020 02:00|01/01/2020 05:10|01/01/2020 05:10|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9200|        0|                N|                 SBGL|                  SBSG|01/01/2020 22:10|01/01/2020 22:10|02/01/2020 01:15|02/01/2020 01:15|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9046|        0|                N|                 SBGR|                  SBBR|01/01/2020 05:50|01/01/2020 05:50|01/01/2020 07:40|01/01/2020 07:40|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9010|        0|                N|                 SBMO|                  SBGR|01/01/2020 19:50|01/01/2020 19:50|01/01/2020 23:00|01/01/2020 23:00|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9009|        0|                N|                 SBGR|                  SBMO|01/01/2020 15:05|01/01/2020 15:05|01/01/2020 18:00|01/01/2020 18:00|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9008|        0|                N|                 SBSG|                  SBGR|01/01/2020 10:20|01/01/2020 10:20|01/01/2020 13:50|01/01/2020 13:50|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9007|        0|                N|                 SBGR|                  SBSG|01/01/2020 06:20|01/01/2020 06:20|01/01/2020 09:40|01/01/2020 09:40|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9006|        0|                N|                 SBJP|                  SBBR|01/01/2020 19:00|01/01/2020 19:00|01/01/2020 21:45|01/01/2020 21:45|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9005|        0|                N|                 SBBR|                  SBSG|01/01/2020 08:20|01/01/2020 08:20|01/01/2020 11:00|01/01/2020 11:00|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9004|        0|                N|                 SBSG|                  SBBR|01/01/2020 11:35|01/01/2020 11:35|01/01/2020 14:20|01/01/2020 14:20|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      9003|        0|                N|                 SBBR|                  SBJP|01/01/2020 15:00|01/01/2020 15:00|01/01/2020 17:35|01/01/2020 17:35|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8211|        0|                I|                 EGYP|                  SBGR|01/01/2020 16:50|01/01/2020 16:50|01/01/2020 21:35|01/01/2020 21:35|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8210|        0|                I|                 SBGR|                  EGYP|01/01/2020 09:30|01/01/2020 09:30|01/01/2020 14:35|01/01/2020 14:35|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8195|        0|                I|                 KMIA|                  SBGR|01/01/2020 10:05|01/01/2020 10:05|01/01/2020 18:25|01/01/2020 18:25|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8194|        0|                I|                 SBGR|                  KMIA|01/01/2020 10:45|01/01/2020 10:45|01/01/2020 18:55|01/01/2020 18:55|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8191|        0|                I|                 KMIA|                  SBGR|01/01/2020 21:10|01/01/2020 21:10|02/01/2020 05:30|02/01/2020 05:30|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8190|        0|                I|                 SBGR|                  KMIA|01/01/2020 23:05|01/01/2020 23:05|02/01/2020 07:15|02/01/2020 07:15|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8189|        0|                I|                 KMIA|                  SBFZ|01/01/2020 18:20|01/01/2020 18:20|02/01/2020 01:25|02/01/2020 01:25|   REALIZADO|                null|   REALIZADO|\n",
      "|               TAM|      8188|        0|                I|                 SBFZ|                  KMIA|01/01/2020 02:40|01/01/2020 02:40|01/01/2020 10:20|01/01/2020 10:20|   REALIZADO|                null|   REALIZADO|\n",
      "+------------------+----------+---------+-----------------+---------------------+----------------------+----------------+----------------+----------------+----------------+------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.toDF(*[col.lower().replace(\" \",\"_\") for col in df.columns])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tipos de Dados no Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "O Apache Spark oferece uma variedade de tipos de dados que podem ser usados para representar informações em DataFrames. Cada tipo de dado tem características específicas que o tornam adequado para diferentes cenários.\n",
    "\n",
    "## Tipos de Dados Primitivos\n",
    "\n",
    "Os tipos de dados primitivos são os blocos de construção fundamentais para representar informações em Spark:\n",
    "\n",
    "| Tipo de Dado   | Descrição                                      | Exemplo de Caso de Uso                     |\n",
    "|-----------------|------------------------------------------------|------------------------------------------|\n",
    "| IntegerType     | Números inteiros de 32 bits                     | Idades, quantidades, índices.             |\n",
    "| LongType        | Números inteiros de 64 bits                     | IDs exclusivos, contagens extensas.      |\n",
    "| FloatType       | Números de ponto flutuante de 32 bits           | Medidas com decimais, preços.             |\n",
    "| DoubleType      | Números de ponto flutuante de 64 bits           | Valores de alta precisão, coordenadas.    |\n",
    "| StringType      | Sequências de caracteres                        | Nomes, descrições, textos.                |\n",
    "| BooleanType     | Valores booleanos (True/False)                 | Marcadores de verdadeiro ou falso.        |\n",
    "| DateType        | Datas                                        | Datas de eventos, vencimentos.            |\n",
    "| TimestampType   | Data e hora                                 | Registro de eventos com horários.        |\n",
    "| BinaryType      | Dados binários                                | Imagens, arquivos binários.               |\n",
    "| NullType        | Valor nulo (ausência de valor)                | Registros incompletos ou ausentes.        |\n",
    "\n",
    "## Tipos de Dados Complexos\n",
    "\n",
    "Os tipos de dados complexos permitem representar informações mais estruturadas:\n",
    "\n",
    "| Tipo de Dado        | Descrição                                    | Exemplo de Caso de Uso                  |\n",
    "|---------------------|----------------------------------------------|---------------------------------------|\n",
    "| ArrayType           | Lista ordenada de elementos                  | Lista de produtos em um pedido.      |\n",
    "| MapType             | Coleção de pares chave-valor                  | Dicionário de configurações.          |\n",
    "| StructType          | Estrutura de dados com campos nomeados       | Registro de funcionário com nome e idade. |\n",
    "| StructField         | Campo dentro de um StructType                | Colunas em um DataFrame.              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_json = df.schema.json()\n",
    "ddl = spark.sparkContext._jvm.org.apache.spark.sql.types.DataType.fromJson(schema_json).toDDL()\n",
    "\n",
    "ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema_method = StructType(\n",
    "    [\n",
    "        StructField('icao_empresa_aerea', StringType()),\n",
    "        StructField('numero_voo', StringType()),\n",
    "        StructField('codigo_di', StringType()),\n",
    "        StructField('codigo_tipo_linha', StringType()),\n",
    "        StructField('icao_aerodromo_origem', StringType()),\n",
    "        StructField('icao_aerodromo_destino', StringType()),\n",
    "        StructField('partida_prevista', StringType()),\n",
    "        StructField('partida_real', StringType()),\n",
    "        StructField('chegada_prevista', StringType()),\n",
    "        StructField('chegada_real', StringType()),\n",
    "        StructField('situacao_voo', StringType()),\n",
    "        StructField('codigo_justificativa', StringType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- icao_empresa_aerea: string (nullable = true)\n",
      " |-- numero_voo: string (nullable = true)\n",
      " |-- codigo_di: string (nullable = true)\n",
      " |-- codigo_tipo_linha: string (nullable = true)\n",
      " |-- icao_aerodromo_origem: string (nullable = true)\n",
      " |-- icao_aerodromo_destino: string (nullable = true)\n",
      " |-- partida_prevista: string (nullable = true)\n",
      " |-- partida_real: string (nullable = true)\n",
      " |-- chegada_prevista: string (nullable = true)\n",
      " |-- chegada_real: string (nullable = true)\n",
      " |-- situacao_voo: string (nullable = true)\n",
      " |-- codigo_justificativa: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .option(\"encoding\",\"utf-8\")\n",
    "    .option(\"delimiter\",\";\") #ou sep\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema_method)\n",
    "    .load(\"data/landing/VRA/\")\n",
    ")\n",
    "\n",
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vra Bronze save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_final\n",
    "    .write\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"append\")\n",
    "    .save(\"/home/app/data/1.bronze/vra/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerodromos Bronze save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_distincts\n",
    "    .write\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"append\")\n",
    "    .save(\"/home/app/data/1.bronze/aerodromos/\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

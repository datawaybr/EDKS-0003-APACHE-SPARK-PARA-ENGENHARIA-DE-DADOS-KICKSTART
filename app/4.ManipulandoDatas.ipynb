{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Manipulação de Datas e Timestamps no Apache Spark\n",
    "\n",
    "O Apache Spark oferece uma variedade de funções para manipular datas e timestamps em DataFrames. Essas funções são úteis para realizar operações de formatação, cálculos de diferença de tempo, extração de componentes de datas e muito mais.\n",
    "\n",
    "## Funções de Manipulação de Datas e Timestamps\n",
    "\n",
    "As funções a seguir são comumente usadas para manipulação de datas e timestamps:\n",
    "\n",
    "| Função                            | Descrição                                                      | Exemplo de Caso de Uso                            |\n",
    "|-----------------------------------|----------------------------------------------------------------|---------------------------------------------------|\n",
    "| `current_date()`                  | Retorna a data atual                                           | Marcar datas de registro.                         |\n",
    "| `current_timestamp()`             | Retorna a data e hora atual                                    | Registrar timestamps de eventos.                  |\n",
    "| `date_add(start_date, days)`      | Adiciona um número de dias a uma data                           | Prever datas futuras com base em eventos passados. |\n",
    "| `date_sub(start_date, days)`      | Subtrai um número de dias de uma data                           | Calcular datas retroativas.                       |\n",
    "| `datediff(end_date, start_date)`  | Calcula o número de dias entre duas datas                      | Medir a diferença entre datas.                     |\n",
    "| `months_between(end_date, start_date, roundOff)` | Calcula o número de meses entre duas datas | Análise de tendências e sazonalidade. |\n",
    "| `year(date)`                      | Extrai o ano de uma data ou timestamp                          | Agrupar dados por ano.                            |\n",
    "| `quarter(date)`                   | Extrai o trimestre de uma data ou timestamp                    | Agrupar dados por trimestre.                      |\n",
    "| `month(date)`                     | Extrai o mês de uma data ou timestamp                          | Agrupar dados por mês.                            |\n",
    "| `dayofmonth(date)`                | Extrai o dia do mês de uma data ou timestamp                   | Analisar padrões de comportamento mensal.          |\n",
    "| `dayofweek(date)`                 | Extrai o dia da semana de uma data ou timestamp                 | Analisar padrões semanais.                         |\n",
    "| `hour(timestamp)`                 | Extrai a hora de um timestamp                                   | Analisar padrões de atividade por hora.             |\n",
    "| `minute(timestamp)`               | Extrai os minutos de um timestamp                              | Analisar padrões de atividade por minuto.           |\n",
    "| `second(timestamp)`               | Extrai os segundos de um timestamp                              | Analisar padrões de atividade por segundo.          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Exemplo\").config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.24\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " icao_empresa_aerea     | TAM              \n",
      " numero_voo             | 9458             \n",
      " codigo_di              | 0                \n",
      " codigo_tipo_linha      | I                \n",
      " icao_aerodromo_origem  | SBGR             \n",
      " icao_aerodromo_destino | SCEL             \n",
      " partida_prevista       | 01/01/2020 06:30 \n",
      " partida_real           | 01/01/2020 06:30 \n",
      " chegada_prevista       | 01/01/2020 10:40 \n",
      " chegada_real           | 01/01/2020 10:40 \n",
      " situacao_voo           | REALIZADO        \n",
      " codigo_justificativa   | null             \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vra = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"/home/app/data/1.bronze/vra/\")\n",
    ")\n",
    "df_vra.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " icao_empresa_aerea     | TAM                 \n",
      " numero_voo             | 9458                \n",
      " codigo_di              | 0                   \n",
      " codigo_tipo_linha      | I                   \n",
      " icao_aerodromo_origem  | SBGR                \n",
      " icao_aerodromo_destino | SCEL                \n",
      " partida_prevista       | 2020-01-01 06:30:00 \n",
      " partida_real           | 2020-01-01 06:30:00 \n",
      " chegada_prevista       | 2020-01-01 10:40:00 \n",
      " chegada_real           | 2020-01-01 10:40:00 \n",
      " situacao_voo           | REALIZADO           \n",
      " codigo_justificativa   | null                \n",
      " tempo_de_voo_real      | 0                   \n",
      " tempo_de_voo_prevista  | 0                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "(\n",
    "    df_vra\n",
    "    .withColumn(\"partida_prevista\", F.to_timestamp(\"partida_prevista\",'dd/MM/yyyy HH:mm'))\n",
    "    .withColumn(\"partida_real\", F.to_timestamp(\"partida_real\",'dd/MM/yyyy HH:mm'))\n",
    "    .withColumn(\"chegada_prevista\", F.to_timestamp(\"chegada_prevista\",'dd/MM/yyyy HH:mm'))\n",
    "    .withColumn(\"chegada_real\", F.to_timestamp(\"chegada_real\",'dd/MM/yyyy HH:mm'))\n",
    "    .withColumn(\"tempo_de_voo_real\", F.datediff(\"chegada_real\",\"partida_real\"))\n",
    "    .withColumn(\"tempo_de_voo_prevista\", F.datediff(\"chegada_prevista\",\"partida_prevista\"))\n",
    "    .show(1, vertical=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " razão_social             | ABSA - AEROLINHAS... \n",
      " icao_iata                | LTG M3               \n",
      " cnpj                     | 00074635000133       \n",
      " atividades_aéreas        | TRANSPORTE AÉREO ... \n",
      " endereço_sede            | AEROPORTO INTERNA... \n",
      " telefone                 | 1155828055           \n",
      " e-mail                   | gar@tam.com.br       \n",
      " decisão_operacional      | DECISÃO Nº 41        \n",
      " data_decisão_operacional | 22/04/2015           \n",
      " validade_operacional     | 23/04/2025           \n",
      " icao                     | LTG                  \n",
      " iata                     | M3                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cia = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"data/1.bronze/air_cia/\")\n",
    ")\n",
    "df_cia.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.sql.functions' has no attribute 'day'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     df_cia\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_decisão_operacional\u001b[39m\u001b[38;5;124m\"\u001b[39m , F\u001b[38;5;241m.\u001b[39mto_date(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_decisão_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd/MM/yyyy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m\"\u001b[39m , F\u001b[38;5;241m.\u001b[39mto_date(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd/MM/yyyy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39myear(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mmonth(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mquarter(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mdayofweek(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday_of_month\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mdayofmonth(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mday\u001b[49m(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidade_operacional\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m1\u001b[39m, vertical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.sql.functions' has no attribute 'day'"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_cia\n",
    "    .withColumn(\"data_decisão_operacional\" , F.to_date(F.col('data_decisão_operacional'),'dd/MM/yyyy'))\n",
    "    .withColumn(\"validade_operacional\" , F.to_date(F.col('validade_operacional'),'dd/MM/yyyy'))\n",
    "    .withColumn(\"year\", F.year(F.col('validade_operacional')))\n",
    "    .withColumn(\"month\", F.month(F.col('validade_operacional')))\n",
    "    .withColumn(\"quarter\", F.quarter(F.col('validade_operacional')))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(F.col('validade_operacional')))\n",
    "    .withColumn(\"day_of_month\", F.dayofmonth(F.col('validade_operacional')))\n",
    "    .withColumn(\"day\", F.day(F.col('validade_operacional')))\n",
    "    .show(1, vertical=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
